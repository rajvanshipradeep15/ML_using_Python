{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\n",
    "Logistic Regression using Python (stasmodel.formula):</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\"><br>\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "### We will be using HR data in this exercise. Refer the Exhibit 1 to understand the feature list. Use the HR data and answer the below questions.\n",
    "\n",
    "1.\tLoad the dataset in Jupyter Notebook using pandas\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset. Report the features, which are correlated at a cut-off of 0.70. What actions will you take on the features, which are highly correlated?\n",
    "3.\tBuild a new feature named LOB_Hike_Offered using LOB and percentage hike offered. Include this as a part of the data frame created in step 1. What assumption are you trying to test with such variables?\n",
    "4.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "5.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "6.\tBuild a model using Gender and Age as independent variable and Status as dependent variable.\n",
    "    >* Are Gender and Age a significant feature in this model?\n",
    "    * What inferences can be drawn from this model? \n",
    "7.\tBuild a model with statsmodel.api to predict the probability of Not Joining. How do you interpret the model outcome? Report the model performance on the test set.\n",
    "8.\tBuild a model with statsmodel.formula.api to predict the probability of Not Joining and report the model performance on the test set. What difference do you observe in the model built here and the one built in step 7.\n",
    "9.\tBuild a model using sklearn package to predict the probability of Not Joining. What difference do you observe in this model compared to model built in step 7 and 8.\n",
    "10.\tFine-tune the cut-off value using cost of misclassification as a strategy. The cut-off should help classify maximum number of Not Joining cases correctly.\n",
    "11.\tFine-tune the cut-off value using youdens index as a strategy. The cut-off should help balance the classification of Joined and Not Joined cases.\n",
    "12.\tApply the cut-off values obtained in step 10 and step 11 on the test set. What inference can be deduced from it?\n",
    "13. Build model using gradient descent to get an intuition about the inner working of optimization algorithms.\n",
    "14. Build model using gradient descent with regularization to get an intution about the inner working of optimization algorithms.\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "\n",
    "|Sl.No.|Name of Variable|Variable Description|\n",
    "|:-------|----------------|:--------------------|\n",
    "|1\t|Candidate reference number|\tUnique number to identify the candidate|\n",
    "|2\t|DOJ extended|Binary variable identifying whether candidate asked for date of joining extension (Yes/No)|\n",
    "|3\t|Duration to accept the offer|\tNumber of days taken by the candidate to accept the offer (continuous variable)|\n",
    "|4\t|Notice period|\tNotice period to be served in the parting company before candidate can join this company (continuous variable)|\n",
    "|5\t|Offered band|\tBand offered to the candidate based on experience and performance in interview rounds (categorical variable labelled C0/C1/C2/C3/C4/C5/C6)|\n",
    "|6\t|Percentage hike (CTC) expected|\tPercentage hike expected by the candidate (continuous variable)|\n",
    "|7\t|Percentage hike offered (CTC)| Percentage hike offered by the company (continuous variable)|\n",
    "|8\t|Percent difference CTC|\tPercentage difference between offered and expected CTC (continuous variable)|\n",
    "|9\t|Joining bonus|\tBinary variable indicating if joining bonus was given or not (Yes/No)|\n",
    "|10\t|Gender|\tGender of the candidate (Male/Female)|\n",
    "|11\t|Candidate source|\tSource from which resume of the candidate was obtained (categorical variables with categories  Employee referral/Agency/Direct)|\n",
    "|12\t|REX (in years)|\tRelevant years of experience of the candidate for the position offered (continuous variable)|\n",
    "|13\t|LOB|\tLine of business for which offer was rolled out (categorical variable)|\n",
    "|14\t|DOB|\tDate of birth of the candidate|\n",
    "|15\t|Joining location|\tCompany location for which offer was rolled out for candidate to join (categorical variable)|\n",
    "|16\t|Candidate relocation status|\tBinary variable indicating whether candidate has to relocate from one city to another city for joining (Yes/No)|\n",
    "|17 |HR status|\tFinal joining status of candidate (Joined/Not-Joined)|\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "To know the environment with the pyhton kernal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn # visualization library based on matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set\n",
    "\n",
    "_Give the correct path to the data_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the ast_note_interactivity kernel option to see the value of multiple statements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv( \"../HR_case/data/IMB533_HR_Data_No_Missing_Value.csv\", \n",
    "                        sep = ',', na_values = ['', ' '])\n",
    "\n",
    "raw_df.columns = raw_df.columns.str.lower().str.replace(' ', '_')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping SLNo and Candidate.Ref as these will not be used for any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if set(['slno','candidate_ref']).issubset(raw_df.columns):\n",
    "    raw_df.drop(['slno','candidate_ref'],axis=1, inplace=True)\n",
    "    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.status.value_counts()\n",
    "#raw_df.describe(include='all').transpose()\n",
    "raw_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a help on the features of a object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = raw_df.dropna(axis=0, how='any', thresh=None, \n",
    "                             subset=None, inplace=False)\n",
    "\n",
    "list(filter_df.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by printing the unique labels in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features = ['duration_to_accept_offer','notice_period','pecent_hike_expected_in_ctc',\n",
    "                      'percent_hike_offered_in_ctc','percent_difference_ctc','rex_in_yrs','age']\n",
    "\n",
    "categorical_features = ['doj_extended','offered_band','joining_bonus','candidate_relocate_actual',\n",
    "                        'gender','candidate_source','lob','location','status']\n",
    "\n",
    "for f in categorical_features:\n",
    "    print(\"\\nThe unique labels in {} is {}\\n\".format(f, filter_df[f].unique()))\n",
    "    print(\"The values in {} is \\n{}\\n\".format(f,  filter_df[f].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature **line of business** it seems that *EAS, Healthcare and MMS* does not have enough observations and may be clubbed together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['lob']=np.where(filter_df['lob'] =='EAS', 'Others', filter_df['lob'])\n",
    "filter_df['lob']=np.where(filter_df['lob'] =='Healthcare', 'Others', filter_df['lob'])\n",
    "filter_df['lob']=np.where(filter_df['lob'] =='MMS', 'Others', filter_df['lob'])\n",
    "filter_df.lob.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **groupby** function of pandas to get deeper insights of the behaviour of people **Joining** or **Not Joining** the company. We will write a generic function to report the mean by any categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by (categorical_features):\n",
    "    return filter_df.groupby(categorical_features).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by(\"doj_extended\")\n",
    "group_by(\"status\")\n",
    "group_by(\"location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Data\n",
    "\n",
    "Plot can be done using the callable functions of \n",
    "\n",
    ">1. pandas library (http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "2. matplotlib library (https://matplotlib.org/) or\n",
    "3. seaborn library (https://seaborn.pydata.org/) which is based on matplotlib and provides interface for drawing attractive statistical graphics.\n",
    "\n",
    "#### 3a. Visualizing the Data using seaborn\n",
    "\n",
    "Write a custom function to create bar plot to visualize the average of numeric features w.r.t each categorical feature. Say, average number of days to accept the offer w.r.t status as joined vs. not joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(xlabel,ylabel):\n",
    "    sn.barplot(x = xlabel, y = ylabel, data= filter_df)\n",
    "    plt.xlabel(xlabel, size = 14)\n",
    "    plt.ylabel(ylabel, size = 14)\n",
    "    #plt.grid(True)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features_set = ['duration_to_accept_offer','notice_period','age']\n",
    "categorical_features_set = ['offered_band','gender','status']\n",
    "\n",
    "for c in categorical_features_set:\n",
    "    for n in numerical_features_set:\n",
    "        bar_plot(c,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:  Without dummy variable coding (Using Statsmodel.formula.api)\n",
    "\n",
    "This is a code with R and Python being used in the same notebook\n",
    "\n",
    "Refer for details: https://www.statsmodels.org/dev/example_formulas.html and https://www.statsmodels.org/dev/examples/notebooks/generated/glm_formula.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the name of all the models in any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(smf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create train and test dataset\n",
    "\n",
    "#### Train and test data split using Python\n",
    "\n",
    "The train and test split can also be done using the **sklearn module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split( filter_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pull the specific attribute needed to build the model is another data frame. This again is more of a hygine practice to not touch the **train** and **test** data set directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "variableUsedinTraining, echo=TRUE,tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "lg_train_df = train_df.filter(['duration_to_accept_offer',\n",
    "                               'notice_period',\n",
    "                               'percent_difference_ctc',\n",
    "                               'rex_in_yrs',\n",
    "                               'age',\n",
    "                               'doj_extended',\n",
    "                               'offered_band',\n",
    "#                               'pecent_hike_expected_in_ctc',\n",
    "#                               'percent_hike_offered_in_ctc',\n",
    "                               'joining_bonus',\n",
    "#                               'candidate_relocate_actual',\n",
    "                               'gender',\n",
    "                               'candidate_source',\n",
    "                               'lob',\n",
    "                               'location',\n",
    "                               'status'\n",
    "                              ], axis = 1)\n",
    "\n",
    "lg_test_df = test_df.filter(['duration_to_accept_offer',\n",
    "                               'notice_period',\n",
    "                               'percent_difference_ctc',\n",
    "                               'rex_in_yrs',\n",
    "                               'age',\n",
    "                               'doj_extended',\n",
    "                               'offered_band',\n",
    "#                               'pecent_hike_expected_in_ctc',\n",
    "#                               'percent_hike_offered_in_ctc',\n",
    "                               'joining_bonus',\n",
    "#                               'candidate_relocate_actual',\n",
    "                               'gender',\n",
    "                               'candidate_source',\n",
    "                               'lob',\n",
    "                               'location',\n",
    "                               'status'\n",
    "                              ], axis = 1)\n",
    "\n",
    "lg_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the formula with the required set of variables to be used in model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_formula = 'C(status) ~ \\\n",
    "            duration_to_accept_offer+ \\\n",
    "            notice_period + \\\n",
    "            percent_difference_ctc + \\\n",
    "            rex_in_yrs + \\\n",
    "            age + \\\n",
    "            C(doj_extended) + \\\n",
    "            C(offered_band) + \\\n",
    "            C(joining_bonus) + \\\n",
    "            C(gender) + \\\n",
    "            C(candidate_source) + \\\n",
    "            C(lob) + \\\n",
    "            C(location)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lg_reg_model = smf.glm(formula=pass_formula, data=lg_train_df, family=sm.families.Binomial()).fit()\n",
    "lg_reg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the significant variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_vars (modelobject):\n",
    "    var_p_vals_df = pd.DataFrame(modelobject.pvalues)\n",
    "    var_p_vals_df['vars'] = var_p_vals_df.index\n",
    "    var_p_vals_df.columns = ['pvals', 'vars']\n",
    "    return list(var_p_vals_df[var_p_vals_df.pvals <= 0.05]['vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_vars = get_significant_vars(lg_reg_model)\n",
    "significant_vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on train data.\n",
    "Two ways to precit the outcome on the **train set**\n",
    "> * Use **predict** function of the model object \n",
    "* Use **get_prediction** function of the model object\n",
    "\n",
    "For the model with dummy variable coding explicetely done, we need to add the constant term to the test set. For the model with dummy variable coding carried out automatically, there is no need to add the constant term to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output with the model with no dummy variable coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretVarImp, echo=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_train_df = lg_reg_model.predict((lg_train_df))\n",
    "predict_train_df.head()\n",
    "\n",
    "predict_train_df = lg_reg_model.get_prediction(lg_train_df)\n",
    "predict_train_df.predicted_mean[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "def get_predictions ( test_class, model, test_data ):\n",
    "    y_pred_df = pd.DataFrame( { 'actual': test_class,\n",
    "                               'predicted_prob': model.get_prediction((test_data)).predicted_mean})\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df = pd.DataFrame(get_predictions(lg_test_df.status, lg_reg_model, lg_test_df))\n",
    "predict_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df['predicted'] = predict_test_df.predicted_prob.map(lambda x: 'Joined' if x > 0.5 else 'Not Joined')\n",
    "predict_test_df[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix\n",
    "\n",
    "We will built classification matrix using the **metrics** method from **sklearn** package. We will also write a custom function to build a classification matrix and use it for reporting the performance measures.\n",
    "\n",
    "#### 3a. Confusion Matrix using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The model without dummy variable coding output: \")\n",
    "confusion_matrix(lg_test_df.status, predict_test_df.predicted)\n",
    "lg_reg_report = (classification_report(lg_test_df.status, predict_test_df.predicted))\n",
    "print(lg_reg_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b Confusion Matrix using generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cm( actual, predicted ):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    cm = metrics.confusion_matrix( actual, predicted )\n",
    "    sn.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [\"Joined\", \"Not Joined\"] , \n",
    "               yticklabels = [\"Joined\", \"Not Joined\"],cmap = 'Blues_r')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Classification Matrix Plot', size = 15);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification matrix plot as reported without dummy variable coding is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm( predict_test_df.actual, predict_test_df.predicted )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performance Measure on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance (clasf_matrix):\n",
    "    measure = pd.DataFrame({\n",
    "                        'sensitivity': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)], \n",
    "                        'specificity': [round(clasf_matrix[1,1]/(clasf_matrix[1,0]+clasf_matrix[1,1]),2)],\n",
    "                        'recall': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)],\n",
    "                        'precision': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[1,0]),2)],\n",
    "                        'overall_acc': [round((clasf_matrix[0,0]+clasf_matrix[1,1])/\n",
    "                                              (clasf_matrix[0,0]+clasf_matrix[0,1]+clasf_matrix[1,0]+clasf_matrix[1,1]),2)]\n",
    "                       })\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(predict_test_df.actual, predict_test_df.predicted)\n",
    "\n",
    "lg_reg_metrics_df = pd.DataFrame(measure_performance(cm))\n",
    "lg_reg_metrics_df\n",
    "\n",
    "print( 'Total Accuracy sklearn: ',np.round( metrics.accuracy_score( lg_test_df.status, predict_test_df.predicted ), 2 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. The optimal cut-off\n",
    "\n",
    "We are going to use model without dummy variable coding to select the optimal cut-off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Select the optimal cut-off value, if:\n",
    "\n",
    "> 1. Cost of Mis-classifying Not Joined as Joined is twice as costly as cost of micalssifying Joined as Not Joined\n",
    "2. Both sensitivity and specificity are equally important\n",
    "\n",
    "The best cut-off is the one which minimizes the misclassification cost (in case of **_option 1_**) or which maximizes the Youden's Index (in case of **_Option 2_**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "modelOptimalCutOff, echo=FALSE,tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "lg_pred_prob_df = lg_reg_model.predict((lg_train_df))\n",
    "n = len(lg_train_df)\n",
    "\n",
    "costs =  pd.DataFrame.from_dict({'Joined': [0,1], 'Not Joined': [2,0]},\n",
    "                    orient='index', columns=['Joined', 'Not Joined'])\n",
    "\n",
    "print(costs)\n",
    "costs.iloc[0][1] #to refer to specific value at a given position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Defining loop function to loop through float values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "     s = start\n",
    "     while s < stop:\n",
    "         yield s\n",
    "         s += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "costCal, echo=TRUE, tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#creating empty vectors to store the results.\n",
    "cutoff = []\n",
    "P11 = [] #correct classification of positive as positive\n",
    "P00 = [] #correct classification of negative as negative\n",
    "P10 = [] #misclassification of positive class to negative class\n",
    "P01 = [] #misclassification of negative class to positive class\n",
    "\n",
    "\n",
    "for i in frange(0.00, 1, 0.05):\n",
    "    predicted_y = lg_pred_prob_df.map(lambda x: 'Joined' if x > i else 'Not Joined')\n",
    "    tbl = metrics.confusion_matrix(lg_train_df.status, predicted_y)\n",
    "    if ( i <= 1):\n",
    "        j = int(20*i)\n",
    "        P01.append(tbl[1,0]/(tbl[1,0] + tbl[1,1]))\n",
    "        P00.append(tbl[1,1]/(tbl[1,0] + tbl[1,1]))\n",
    "        P10.append(tbl[0,1]/(tbl[0,0] + tbl[0,1]))\n",
    "        P11.append(tbl[0,0]/(tbl[0,0] + tbl[0,1]))\n",
    "        cutoff.append(i)\n",
    "\n",
    "d = {'cutoff':cutoff,'P10':P10,'P01': P01,'P00': P00,'P11':P11}\n",
    "df_cost_table = pd.DataFrame(d, columns=['cutoff','P00','P01','P10','P11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The table summarizing the optimal cut-off value:\n",
    "\n",
    "_write the cost.table into a csv file_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "modelOptimalCutoffTable, echo=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "df_cost_table['msclaf_cost'] = df_cost_table.P10*costs.iloc[0][1]+df_cost_table.P01*costs.iloc[1][0]\n",
    "df_cost_table['youden_index'] = df_cost_table.P00+df_cost_table.P11 -1\n",
    "df_cost_table\n",
    "\n",
    "#write to csv\n",
    "#df_cost_table.to_csv(\"optimal_Cutoff_caret.csv\", sep=',')\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Confusion Matrix using Optimal Cut-off\n",
    "\n",
    "The probability value along with the optimal cut-off can be used to build confusion matrix. We will use the **draw_cm** and **performance_measure** functions defined previously to report the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "modelValidation, echo=FALSE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_test_df['predicted'] = predict_test_df.predicted_prob.map(lambda x: 'Joined' if x > 0.8 else 'Not Joined') \n",
    "predict_test_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm( predict_test_df.actual, predict_test_df.predicted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(predict_test_df.actual, predict_test_df.predicted)\n",
    "\n",
    "pd.DataFrame(measure_performance(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 6. ROC Plot on the test data\n",
    "\n",
    "ROCR package can be used to evaluate the model performace on the test data. The same package can also be used to get the model performace on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs, drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the labels to 0/1 code so that it can be passed to the sklearn identifies the positive and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df['predicted_code'] = predict_test_df.predicted.replace(('Joined', 'Not Joined'), (1, 0))\n",
    "predict_test_df['actual_code'] = predict_test_df.actual.replace(('Joined', 'Not Joined'), (1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = draw_roc(predict_test_df.actual_code, predict_test_df.predicted_prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = metrics.roc_auc_score( predict_test_df.actual_code, predict_test_df.predicted_prob  )\n",
    "round( float( auc_score ), 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
