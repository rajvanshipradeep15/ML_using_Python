{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\n",
    "XGboost using Python (sklearn):</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\"><br>\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "### We will be using HR data in this exercise. Refer the Exhibit 1 to understand the feature list. Use the HR data and answer the below questions.\n",
    "\n",
    "1.\tLoad the dataset in Jupyter Notebook using pandas\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset. Report the features, which are correlated at a cut-off of 0.70. What actions will you take on the features, which are highly correlated?\n",
    "3.\tBuild a new feature named LOB_Hike_Offered using LOB and percentage hike offered. Include this as a part of the data frame created in step 1. What assumption are you trying to test with such variables?\n",
    "4.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "5.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "6.\tBuild a model using Gender and Age as independent variable and Status as dependent variable.\n",
    "    >* Are Gender and Age a significant feature in this model?\n",
    "    * What inferences can be drawn from this model? \n",
    "8.\tBuild a model using sklearn package to predict the probability of Not Joining.\n",
    "\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "\n",
    "|Sl.No.|Name of Variable|Variable Description|\n",
    "|:-------|----------------|:--------------------|\n",
    "|1\t|Candidate reference number|\tUnique number to identify the candidate|\n",
    "|2\t|DOJ extended|Binary variable identifying whether candidate asked for date of joining extension (Yes/No)|\n",
    "|3\t|Duration to accept the offer|\tNumber of days taken by the candidate to accept the offer (continuous variable)|\n",
    "|4\t|Notice period|\tNotice period to be served in the parting company before candidate can join this company (continuous variable)|\n",
    "|5\t|Offered band|\tBand offered to the candidate based on experience and performance in interview rounds (categorical variable labelled C0/C1/C2/C3/C4/C5/C6)|\n",
    "|6\t|Percentage hike (CTC) expected|\tPercentage hike expected by the candidate (continuous variable)|\n",
    "|7\t|Percentage hike offered (CTC)| Percentage hike offered by the company (continuous variable)|\n",
    "|8\t|Percent difference CTC|\tPercentage difference between offered and expected CTC (continuous variable)|\n",
    "|9\t|Joining bonus|\tBinary variable indicating if joining bonus was given or not (Yes/No)|\n",
    "|10\t|Gender|\tGender of the candidate (Male/Female)|\n",
    "|11\t|Candidate source|\tSource from which resume of the candidate was obtained (categorical variables with categories  Employee referral/Agency/Direct)|\n",
    "|12\t|REX (in years)|\tRelevant years of experience of the candidate for the position offered (continuous variable)|\n",
    "|13\t|LOB|\tLine of business for which offer was rolled out (categorical variable)|\n",
    "|14\t|DOB|\tDate of birth of the candidate|\n",
    "|15\t|Joining location|\tCompany location for which offer was rolled out for candidate to join (categorical variable)|\n",
    "|16\t|Candidate relocation status|\tBinary variable indicating whether candidate has to relocate from one city to another city for joining (Yes/No)|\n",
    "|17 |HR status|\tFinal joining status of candidate (Joined/Not-Joined)|\n",
    "\n",
    "***\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "To know the environment with the pyhton kernal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn # visualization library based on matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set\n",
    "\n",
    "_Give the correct path to the data_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the ast_note_interactivity kernel option to see the value of multiple statements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv( \"../HR_case/data/HR_Data_No_Missing_Value.csv\", \n",
    "                        sep = ',', na_values = ['', ' '])\n",
    "\n",
    "raw_df.columns = raw_df.columns.str.lower().str.replace(' ', '_')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping SLNo and Candidate.Ref as these will not be used for any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if set(['slno','candidate_ref']).issubset(raw_df.columns):\n",
    "    raw_df.drop(['slno','candidate_ref'],axis=1, inplace=True)\n",
    "    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.status.value_counts()\n",
    "#raw_df.describe(include='all').transpose()\n",
    "raw_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a help on the features of a object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = raw_df.dropna(axis=0, how='any', thresh=None, \n",
    "                             subset=None, inplace=False)\n",
    "\n",
    "list(filter_df.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by printing the unique labels in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features = ['duration_to_accept_offer','notice_period','pecent_hike_expected_in_ctc',\n",
    "                      'percent_hike_offered_in_ctc','percent_difference_ctc','rex_in_yrs','age']\n",
    "\n",
    "categorical_features = ['doj_extended','offered_band','joining_bonus','candidate_relocate_actual',\n",
    "                        'gender','candidate_source','lob','location','status']\n",
    "\n",
    "for f in categorical_features:\n",
    "    print(\"\\nThe unique labels in {} is {}\\n\".format(f, filter_df[f].unique()))\n",
    "    print(\"The values in {} is \\n{}\\n\".format(f,  filter_df[f].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature **line of business** it seems that *EAS, Healthcare and MMS* does not have enough observations and may be clubbed together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['lob']=np.where(filter_df['lob'] =='EAS', 'Others', filter_df['lob'])\n",
    "filter_df['lob']=np.where(filter_df['lob'] =='Healthcare', 'Others', filter_df['lob'])\n",
    "filter_df['lob']=np.where(filter_df['lob'] =='MMS', 'Others', filter_df['lob'])\n",
    "filter_df.lob.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **groupby** function of pandas to get deeper insights of the behaviour of people **Joining** or **Not Joining** the company. We will write a generic function to report the mean by any categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by (categorical_features):\n",
    "    return filter_df.groupby(categorical_features).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by(\"doj_extended\")\n",
    "group_by(\"status\")\n",
    "group_by(\"location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Data\n",
    "\n",
    "Plot can be done using the callable functions of \n",
    "\n",
    ">1. pandas library (http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "2. matplotlib library (https://matplotlib.org/) or\n",
    "3. seaborn library (https://seaborn.pydata.org/) which is based on matplotlib and provides interface for drawing attractive statistical graphics.\n",
    "\n",
    "#### 3a. Visualizing the Data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(data, group_by, xlabel,ylabel):\n",
    "    pd.crosstab(data,group_by).plot(kind='density')\n",
    "    plt.xlabel(xlabel, size = 14)\n",
    "    plt.ylabel(ylabel, size = 14)\n",
    "    plt.title('Plot', size = 18)\n",
    "    plt.grid(True)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((0,x2,y1,y2))\n",
    "    plt.show()\n",
    "    #plt.subplot(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features_set = ['duration_to_accept_offer','notice_period','age']\n",
    "categorical_features_set = ['offered_band','gender','status']\n",
    "\n",
    "for c in categorical_features_set:\n",
    "    for n in numerical_features_set:\n",
    "        hist_plot(filter_df[n], filter_df[c], n,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: \n",
    "\n",
    "### Dummy Variable coding\n",
    "\n",
    "Remove the response variable from the dataset¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = list(filter_df.columns)\n",
    "X_features.remove('status')\n",
    "X_features.remove('pecent_hike_expected_in_ctc')\n",
    "X_features.remove('percent_hike_offered_in_ctc')\n",
    "X_features.remove('candidate_relocate_actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['doj_extended','offered_band','joining_bonus','gender','candidate_source','lob','location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_df = pd.get_dummies( filter_df[X_features], columns = categorical_features, drop_first = False )\n",
    "encoded_Y_df = pd.get_dummies( filter_df['status'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "encoded_X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = encoded_Y_df.filter(['Joined'], axis =1)\n",
    "X = encoded_X_df\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split using Python\n",
    "\n",
    "The train and test split can also be done using the **sklearn module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Using the **xgboost** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install this package with conda run the following:\n",
    "\n",
    "* conda install -c conda-forge xgboost\n",
    "\n",
    "If the above does not work try below one:\n",
    "\n",
    "* conda install -c conda-forge/label/gcc7 xgboost\n",
    "* conda install -c conda-forge/label/cf201901 xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "#from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.XGBClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost parameters\n",
    "\n",
    "The overall parameters have been divided into 3 categories by XGBoost authors:\n",
    "\n",
    "* General Parameters: Guide the overall functioning\n",
    "* Booster Parameters: Guide the individual booster (tree/regression) at each step\n",
    "* Learning Task Parameters: Guide the optimization performed\n",
    "\n",
    "### General Parameters\n",
    "These define the overall functionality of XGBoost.\n",
    "\n",
    "1. booster [default=gbtree]\n",
    "       Select the type of model to run at each iteration. It has 2 options:\n",
    "           gbtree: tree-based models\n",
    "           gblinear: linear models\n",
    "2. silent [default=0]:\n",
    "       Silent mode is activated is set to 1, i.e. no running messages will be printed. It’s generally good to keep it 0 as the messages might help in understanding the model.\n",
    "3. nthread [default to maximum number of threads available if not set]\n",
    "        This is used for parallel processing and number of cores in the system should be entered. If you wish to run on all cores, value should not be entered and algorithm will detect automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booster Parameters\n",
    "Though there are 2 types of boosters. Below are the parameters of tree booster (it always outperforms the linear booster and thus the later is rarely used).\n",
    "\n",
    "1. learning_rate or eta [default=0.1]\n",
    "        * Analogous to learning rate in GBM. \n",
    "        * Makes the model more robust by shrinking the weights on each step. \n",
    "        * Typical final values to be used: 0.01-0.2\n",
    "2. min_child_weight [default=1]\n",
    "        * Defines the minimum sum of weights of all observations required in a child. \n",
    "        * This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n",
    "        * Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "        * Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "3. max_depth [default=3]\n",
    "        * The maximum depth of a tree, same as GBM.\n",
    "        * Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "        * Should be tuned using CV.\n",
    "        * Typical values: 3-10\n",
    "4. max_leaf_nodes\n",
    "        * The maximum number of terminal nodes or leaves in a tree.\n",
    "        * Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "        * If this is defined, GBM will ignore max_depth.\n",
    "5. gamma [default=0]\n",
    "        * A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.\n",
    "        * Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "6. max_delta_step [default=0]\n",
    "        * In maximum delta step we allow each tree’s weight estimation to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative.\n",
    "        * Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n",
    "        * This is generally not used but you can explore further if you wish.\n",
    "7. subsample [default=1]\n",
    "        * Denotes the fraction of observations to be randomly samples for each tree.\n",
    "        * Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "        * Typical values: 0.5-1\n",
    "8. colsample_bytree [default=1]\n",
    "        * Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
    "        * Typical values: 0.5-1\n",
    "9. colsample_bylevel [default=1]\n",
    "        * Denotes the subsample ratio of columns for each split, in each level.\n",
    "        * May not be needed because subsample and colsample_bytree will do the job.\n",
    "10. reg_alpha [default=0]\n",
    "        * L1 regularization term on weight (analogous to Lasso regression)\n",
    "        * Can be used in case of very high dimensionality so that the algorithm runs faster when implemented\n",
    "11. reg_lambda [default=1]\n",
    "        * L2 regularization term on weights (analogous to Ridge regression)\n",
    "        * This used to handle the regularization part of XGBoost. \n",
    "        * It should be explored to reduce overfitting.\n",
    "\n",
    "12. scale_pos_weight [default=1]\n",
    "        * A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Task Parameters\n",
    "These parameters are used to define the optimization objective the metric to be calculated at each step.\n",
    "\n",
    "1. objective [default=reg:linear]\n",
    "        * This defines the loss function to be minimized. Mostly used values are:\n",
    "                binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "                multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities). you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "                multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "2. seed [default=0]\n",
    "       * The random number seed.\n",
    "       * Can be used for generating reproducible results and also for parameter tuning.\n",
    "       \n",
    "\n",
    "More details about the parameters: https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement  XG boost with RandomizedSearchCV\n",
    "\n",
    "Refer here to understand the details of parallel processing: https://stackoverflow.com/questions/32673579/scikit-learn-general-question-about-parallel-computing while using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = { \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "               \"gamma\": uniform(0, 0.5),\n",
    "               \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "               \"max_depth\": randint(2, 6), # default 3\n",
    "               \"n_estimators\": randint(100, 150), # default 100\n",
    "               \"subsample\": uniform(0.6, 0.4)}\n",
    "\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To report the performance on the selected KPI use `sklearn.metrics.SCORERS.keys()` to get the list of all the metrics and pass the relevant one in `RandomizedSearchCV` or `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalanced Dataset\n",
    "\n",
    "For common cases such as ads clickthrough log, the dataset is extremely imbalanced. This can affect the training of XGBoost model, and there are two ways to improve it.\n",
    "\n",
    "1. If you care only about the overall performance metric (AUC) of your prediction\n",
    "\n",
    "        * Balance the positive and negative weights via scale_pos_weight\n",
    "        * Use AUC for evaluation\n",
    "\n",
    "2. If you care about predicting the right probability\n",
    "\n",
    "        * In such a case, you cannot re-balance the dataset\n",
    "        * Set parameter max_delta_step to a finite number (say 1) to help convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=1)\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "xg_best_model = RandomizedSearchCV(estimator = xgb_model, \n",
    "                                   param_distributions = random_grid, scoring = \"precision\",\n",
    "                                   n_iter = 50, cv = 3, verbose=2, \n",
    "                                   return_train_score=True,random_state=42, n_jobs = -2, pre_dispatch =2)\n",
    "\n",
    "\n",
    "xg_best_model.fit(X_train, y_train.values.ravel())\n",
    "# Fit the random search model\n",
    "xg_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to fine tuning the parameters\n",
    "\n",
    "In general, the fine tuning of all the parameters in one step can be time consuming and limited by the infrastructure. We can follow the below sequence to fine tune the parameters of xgboost:\n",
    "\n",
    "1. Start with a fixed learning rate (say 0.1) and fixed number of trees (n_estimator = 500)\n",
    "\n",
    "Iteration 1: \n",
    "* max_depth\n",
    "* min_child_weight\n",
    "\n",
    "Iteration 2: Keeping the parameter values from above iterations.\n",
    "* gamma\n",
    "\n",
    "**Note the above two steps are critical to come out of model overfitting issue.**\n",
    "\n",
    "Iteration 3: Keeping the parameter values from above iterations.\n",
    "* subsample:\n",
    "* colsample_bytree\n",
    "\n",
    "The that subsample, colsample_bytree will lead to adding randomness to make training robust to noise (another way to deal with overfitting). You can also reduce stepsize learning_rate/eta to deal with overfitting issue. Remember to increase num_round when you do so.\n",
    "\n",
    "Iteration 4: Keeping the parameter values from above iterations.\n",
    "* reg_alpha\n",
    "\n",
    "\n",
    "2. At the end with all the paramters fixed, change learning rate and n_estimator using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the parameter\n",
    "\n",
    "The best model has the following parameter selected from the random search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xg_best_model.best_params_\n",
    "\n",
    "xg_best_model.best_estimator_\n",
    "\n",
    "xg_best_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with Cross Validation\n",
    "\n",
    "Random search allows to narrow down the range for each hyperparameter. Thus we know where to concentrate the search, to fine tune the model further. \n",
    "\n",
    "`GridSearchCV`, is a method that instead of sampling randomly from a distribution, evaluates all combinations which are defined. The grid search can be called `from sklearn.model_selection import GridSearchCV`\n",
    "\n",
    "You are encouraged to fine tune the model further using Grid Search\n",
    "\n",
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on train data.\n",
    "\n",
    "To predict the outcome on the **train set**\n",
    "> * Use **predict** function of the model object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretVarImp, echo=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "predict_class_train_df = pd.DataFrame(xg_best_model.predict(X_train))\n",
    "predict_class_train_df.head()\n",
    "\n",
    "predict_porb_train_df = pd.DataFrame(xg_best_model.predict_proba(X_train))\n",
    "predict_porb_train_df.iloc[:,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output clearly shows that the predcited class is the one for which the calculated probability is more compared to the calculated probability of the other class.\n",
    "\n",
    "### 2. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "def get_predictions ( test_class, model, test_data ):\n",
    "    predicted_df = pd.DataFrame(model.predict(test_data))\n",
    "    y_pred_df = pd.concat([test_class.reset_index(drop=True), predicted_df], axis =1)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving label to the Y column of the test set by using the dictionary data type in python. This is being done for the model which was built using dummy variable coding. It will be used to generate confusion matrix at a later time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_series = y_test\n",
    "train_series = y_train\n",
    "\n",
    "\n",
    "\n",
    "class_test_df = test_series.replace({'Joined':{1:\"Joined\", 0:\"Not Joined\"}})\n",
    "class_test_df.rename({'Joined': 'actual'}, axis='columns', inplace=True )\n",
    "\n",
    "status_dict = {1:\"Joined\", 0:\"Not Joined\"}\n",
    "class_train_df = train_series.replace({'Joined':status_dict})\n",
    "class_train_df.rename({'Joined': 'actual'}, axis='columns', inplace=True )\n",
    "\n",
    "class_test_df.actual.value_counts()\n",
    "class_train_df.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_test_df = pd.DataFrame(get_predictions(class_test_df.actual, xg_best_model, X_test))\n",
    "predict_test_df.rename(columns = {0:'prediction'}, inplace=True)\n",
    "\n",
    "predict_test_df = predict_test_df.replace(dict(prediction=status_dict))\n",
    "predict_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix\n",
    "\n",
    "We will built classification matrix using the **metrics** method from **sklearn** package. We will also write a custom function to build a classification matrix and use it for reporting the performance measures.\n",
    "\n",
    "To understand the concept of micro average and macro average:\n",
    "\n",
    "https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "\n",
    "#### 3a. Confusion Matrix using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The model with dummy variable coding output: \")\n",
    "confusion_matrix(predict_test_df.actual, predict_test_df.prediction)\n",
    "lg_reg_report = (classification_report(predict_test_df.actual, predict_test_df.prediction))\n",
    "print(lg_reg_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b Confusion Matrix using generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cm( actual, predicted ):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    cm = metrics.confusion_matrix( actual, predicted )\n",
    "    sn.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [\"Joined\", \"Not Joined\"] , \n",
    "               yticklabels = [\"Joined\", \"Not Joined\"],cmap = 'Blues_r')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Classification Matrix Plot', size = 15);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification matrix plot as reported with dummy variable coding is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm( predict_test_df.actual, predict_test_df.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performance Measure on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance (clasf_matrix):\n",
    "    measure = pd.DataFrame({\n",
    "                        'sensitivity': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)], \n",
    "                        'specificity': [round(clasf_matrix[1,1]/(clasf_matrix[1,0]+clasf_matrix[1,1]),2)],\n",
    "                        'recall': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)],\n",
    "                        'precision': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[1,0]),2)],\n",
    "                        'overall_acc': [round((clasf_matrix[0,0]+clasf_matrix[1,1])/\n",
    "                                              (clasf_matrix[0,0]+clasf_matrix[0,1]+clasf_matrix[1,0]+clasf_matrix[1,1]),2)]\n",
    "                       })\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(predict_test_df.actual, predict_test_df.prediction)\n",
    "\n",
    "lg_reg_metrics_df = pd.DataFrame(measure_performance(cm))\n",
    "lg_reg_metrics_df\n",
    "\n",
    "print( 'Total Accuracy sklearn: ',np.round( metrics.accuracy_score( predict_test_df.actual, predict_test_df.prediction ), 2 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
