{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\n",
    "Random Forest using Python (sklearn):</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\"><br>\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "### We will be using Earnings Manipulation data (fraud_data.csv) in this exercise. Refer the Exhibit 1 to understand the feature list. Use the data and answer the below questions.\n",
    "\n",
    "> 1.\tLoad the dataset in Jupyter Notebook using pandas\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset. Report the features, which are correlated at a cut-off of 0.70. What actions will you take on the features, which are highly correlated?\n",
    "3.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "4.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "5.\tUse sklearn package to build a random forest model using `Status` as a dependent variable and all other features as independent variable. Report the model performance on the test set.\n",
    "6.\tUse sklearn model selection module to fine-tune the model parameters of random forest model. Report the model performance on the test set.\n",
    "\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "\n",
    "|Sl. No.|\tName of Variable|\tVariable Description|\n",
    "|--------|--------------|------------------|\n",
    "|1\t|Company ID\t|Unique Identifier|\n",
    "|2 |\tDSRI\t|Days’ Sales in Receivables Index (DSRI): A large increase in receivable days might suggest accelerated revenue recognition to inflate profits.|\n",
    "|3\t|GMI\t|Gross Margin Index (GMI): A deteriorating gross margin sends a negative signal about a firm’s prospects and creates an incentive to inflate profits.|\n",
    "|4\t|AQI\t |Asset Quality Index (AQI): An increase in long term assets (for example, the capitalisation of costs), other than property plant and equipment, relative to total assets indicates that a firm has potentially increased its involvement in cost deferral to inflate profits.|\n",
    "|5\t|SGI\t|Sales Growth Index (SGI): High sales growth does not imply manipulation but high growth companies are more likely to commit financial fraud because their financial position and capital needs put pressure on managers to achieve earnings targets. If growth firms face large stock prices losses at the first indication of a slowdown, they may have greater incentives to manipulate earnings.|\n",
    "|6\t|DEPI \t |Depreciation (DEPI): A falling level of depreciation relative to net fixed assets raises the possibility that a firm has revised upwards the estimated useful life of assets, or adopted a new method that is income increasing.|\n",
    "|7\t|SGAI\t|Sales, General and Administrative Expenses (SGAI): Analysts might interpret a disproportionate increase in SG&A relative to sales as a negative signal about a firm’s future prospects, thereby creating an inventive to inflate profits.|\n",
    "|8\t|ACCR\t|Accruals to Total Assets (ACCR): Total accruals are calculated as the change in working capital (other than cash) less depreciation relative to total assets. Accruals, or a portion thereof, reflect the extent to which managers make discretionary accounting choices to alter earnings. A higher level of accruals is, therefore, associated with a higher likelihood of profit manipulation.|\n",
    "|9\t|LEVI\t|Leverage Index (LEVI): Leverage is measured as total debt relative to total assets. An increase in leverage creates an incentive to manipulate profits in order to meet debt covenants.|\n",
    "|10|\tStatus\t|Manipulator – Yes, Non Manipulator – No|\n",
    "\n",
    "***\n",
    "\n",
    "Learn more about random forest: https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#intro\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "To know the environment with the pyhton kernal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn # visualization library based on matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set\n",
    "\n",
    "_Give the correct path to the data_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the ast_note_interactivity kernel option to see the value of multiple statements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv( \"../Earnings_Manipulation_case/data/fraud_data.csv\", \n",
    "                        sep = ',', na_values = ['', ' '])\n",
    "\n",
    "raw_df.columns = raw_df.columns.str.lower().str.replace(' ', '_')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping company_id as these will not be used for any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if set(['company_id']).issubset(raw_df.columns):\n",
    "    raw_df.drop(['company_id'],axis=1, inplace=True)\n",
    "    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.status.value_counts()\n",
    "#raw_df.describe(include='all').transpose()\n",
    "raw_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a help on the features of a object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = raw_df.dropna(axis=0, how='any', thresh=None, \n",
    "                             subset=None, inplace=False)\n",
    "\n",
    "list(filter_df.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by printing the unique labels in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features = ['dsri', 'gmi', 'aqi', 'sgi', 'depi', 'sgai', 'accr', 'levi']\n",
    "\n",
    "categorical_features = ['status']\n",
    "\n",
    "for f in categorical_features:\n",
    "    print(\"\\nThe unique labels in {} is {}\\n\".format(f, filter_df[f].unique()))\n",
    "    print(\"The values in {} is \\n{}\\n\".format(f,  filter_df[f].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **groupby** function of pandas to get deeper insights on Manipulators **Yes** or **No**. We will write a generic function to report the mean by any categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by (categorical_features):\n",
    "    return filter_df.groupby(categorical_features).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by(\"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Data\n",
    "\n",
    "Plot can be done using the callable functions of \n",
    "\n",
    ">1. pandas library (http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "2. matplotlib library (https://matplotlib.org/) or\n",
    "3. seaborn library (https://seaborn.pydata.org/) which is based on matplotlib and provides interface for drawing attractive statistical graphics.\n",
    "\n",
    "#### 3a. Visualizing the Data using seaborn\n",
    "\n",
    "Write a custom function to create bar plot to visualize the average of numeric features w.r.t each categorical feature. Say, numeric features w.r.t status as status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(xlabel,ylabel,xcnt,ycnt):\n",
    "    sn.barplot(x = xlabel, y = ylabel, data= filter_df, ax = axes[xcnt,ycnt])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features_set = ['dsri', 'gmi', 'aqi', 'sgi', 'depi', 'sgai', 'accr', 'levi']\n",
    "categorical_features_set = ['status']\n",
    "\n",
    "xcnt=0\n",
    "ycnt = 0\n",
    "fig, axes = plt.subplots(4,2, figsize=(10,12))\n",
    "fig.subplots_adjust(hspace = 1, wspace=.5)\n",
    "\n",
    "for c in categorical_features_set:\n",
    "    for n in numerical_features_set:\n",
    "        bar_plot(c,n,xcnt,ycnt)\n",
    "        if ycnt <1:\n",
    "            ycnt = ycnt+1\n",
    "        else:\n",
    "            ycnt = 0\n",
    "            xcnt = xcnt+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Write a custom function to create boxplot plot to understand the outliers in the numeric features w.r.t status\n",
    "* Write a custom function to create histogram plot to visualize the average of numeric features w.r.t status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: \n",
    "\n",
    "### Dummy Variable coding\n",
    "\n",
    "Remove the response variable from the dataset¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = list(filter_df.columns)\n",
    "X_features.remove('status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_df = pd.get_dummies( filter_df[X_features], drop_first = False )\n",
    "encoded_Y_df = pd.get_dummies( filter_df['status'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.get_dummies\n",
    "encoded_Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "encoded_X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = encoded_Y_df.filter(['Yes'], axis =1)\n",
    "X = encoded_X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split using Python\n",
    "\n",
    "The train and test split can also be done using the **sklearn module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.Yes.value_counts()\n",
    "\n",
    "y_train.Yes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Using the **sklearn** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble #linear_model, ensemble, neural_network, naive bayes, svm, tree\n",
    "#dir(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretModel, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#?ensemble.GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretModel, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The “balanced” mode uses the values of y to automatically adjust weights \n",
    "inversely proportional to class frequencies in the input data as \n",
    "n_samples / (n_classes * np.bincount(y))\n",
    "\"\"\"\n",
    "\n",
    "rf_model = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train,y_train.values.ravel())\n",
    "#rf_model.fit(os_data_X,os_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with above approach is to understand which combination is the best. Should we have made a tree with `max_depth` as 4 and `min_sample_leaf` as 30 or should there have been other combination. Searching the grid for the best combination can be taken care of by `RandomizedSearchCV` method of `model_selection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Random Search\n",
    "Refer here to understand the details of parallel processing: https://stackoverflow.com/questions/32673579/scikit-learn-general-question-about-parallel-computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create search space\n",
    "\n",
    "To use RandomizedSearchCV, create a parameter grid from where sample will be picked during model building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100,120,150,200, 240, 400, 500]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,3,4,5,6,7,8,9]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [50, 75, 100]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [30, 35, 40]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# How to remove the class imbalance\n",
    "class_weight=['balanced_subsample','balanced']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'max_features': max_features,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': class_weight}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To report the performance on the selected KPI use `sklearn.metrics.SCORERS.keys()` to get the list of all the metrics and pass the relevant one in `RandomizedSearchCV` or `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model = ensemble.RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_best_model = RandomizedSearchCV(estimator = rf_model, \n",
    "                               param_distributions = random_grid, scoring = \"precision\",\n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -2, pre_dispatch =2)\n",
    "# Fit the random search model\n",
    "rf_best_model\n",
    "rf_best_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the parameter\n",
    "\n",
    "The best model has the following parameter selected from the random search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_best_model.best_params_\n",
    "\n",
    "rf_best_model.best_estimator_\n",
    "\n",
    "rf_best_model.best_score_\n",
    "\n",
    "#rf__best_model.best_index_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Model with Grid Search\n",
    "\n",
    "Random search allows to narrow down the range for each hyperparameter. Thus we know where to concentrate the search, to fine tune the model further. \n",
    "\n",
    "`GridSearchCV`, is a method that instead of sampling randomly from a distribution, evaluates all combinations which are defined. The grid search can be called `from sklearn.model_selection import GridSearchCV`\n",
    "\n",
    "You are encouraged to fine tune the model further using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on train data.\n",
    "\n",
    "To predict the outcome on the **train set**\n",
    "> * Use **predict** function of the model object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretVarImp, echo=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_class_train_df = pd.DataFrame(rf_best_model.predict(X_train))\n",
    "predict_class_train_df.head()\n",
    "\n",
    "predict_porb_train_df = pd.DataFrame(rf_best_model.predict_proba(X_train))\n",
    "predict_porb_train_df.iloc[:,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output clearly shows that the predcited class is the one for which the calculated probability is more compared to the calculated probability of the other class.\n",
    "\n",
    "### 2. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "def get_predictions ( test_class, model, test_data ):\n",
    "    predicted_df = pd.DataFrame(model.predict_proba(test_data))\n",
    "    y_pred_df = pd.concat([test_class.reset_index(drop=True), predicted_df.iloc[:,1:]], axis =1)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving label to the Y column of the test set by using the dictionary data type in python. This is being done for the model which was built using dummy variable coding. It will be used to generate confusion matrix at a later time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.Yes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_series = y_test\n",
    "train_series = y_train\n",
    "\n",
    "status_dict = {1:\"Yes\", 0:\"No\"}\n",
    "\n",
    "y_test_df = test_series.replace(dict(Yes=status_dict))\n",
    "y_test_df.rename({'Yes': 'status'}, axis='columns', inplace=True )\n",
    "\n",
    "y_train_df = train_series.replace(dict(Yes=status_dict))\n",
    "\n",
    "y_train_df.rename({'Yes': 'status'}, axis='columns', inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_test_df = pd.DataFrame(get_predictions(y_test_df.status, rf_best_model, X_test))\n",
    "predict_test_df.rename(columns = {1:'predicted_prob'}, inplace=True)\n",
    "predict_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df['predicted'] = predict_test_df.predicted_prob.map(lambda x: 'Yes' if x > 0.5 else 'No')\n",
    "predict_test_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix\n",
    "\n",
    "We will built classification matrix using the **metrics** method from **sklearn** package. We will also write a custom function to build a classification matrix and use it for reporting the performance measures.\n",
    "\n",
    "To understand the concept of micro average and macro average:\n",
    "\n",
    "https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "\n",
    "#### 3a. Confusion Matrix using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The model with dummy variable coding output: \")\n",
    "confusion_matrix(predict_test_df.status, predict_test_df.predicted)\n",
    "rf_report = (classification_report(predict_test_df.status, predict_test_df.predicted))\n",
    "print(rf_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b Confusion Matrix using generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cm( actual, predicted ):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    cm = metrics.confusion_matrix( actual, predicted )\n",
    "    sn.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [\"No\", \"Yes\"] , \n",
    "               yticklabels = [\"No\", \"Yes\"],cmap = 'Blues_r')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Classification Matrix Plot', size = 15);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification matrix plot as reported with dummy variable coding is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm( predict_test_df.status, predict_test_df.predicted )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performance Measure on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance (clasf_matrix):\n",
    "    measure = pd.DataFrame({\n",
    "                        'specificity': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)], \n",
    "                        'sensitivity': [round(clasf_matrix[1,1]/(clasf_matrix[1,0]+clasf_matrix[1,1]),2)],\n",
    "                        'recall': [round(clasf_matrix[1,1]/(clasf_matrix[1,0]+clasf_matrix[1,1]),2)],\n",
    "                        'precision': [round(clasf_matrix[1,1]/(clasf_matrix[0,1]+clasf_matrix[1,1]),2)],\n",
    "                        'overall_acc': [round((clasf_matrix[0,0]+clasf_matrix[1,1])/\n",
    "                                              (clasf_matrix[0,0]+clasf_matrix[0,1]+clasf_matrix[1,0]+clasf_matrix[1,1]),2)]\n",
    "                       })\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(predict_test_df.status, predict_test_df.predicted)\n",
    "\n",
    "lg_reg_metrics_df = pd.DataFrame(measure_performance(cm))\n",
    "lg_reg_metrics_df\n",
    "\n",
    "print( 'Total Accuracy sklearn: ',np.round( metrics.accuracy_score( predict_test_df.status, predict_test_df.predicted ), 2 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
