{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\n",
    "OLS Regression using Python (stasmodel.formula.api):</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\"><br>\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "### We will be using DAD hospital data in this exercise. Refer the Exhibit 1 to understand the feature list. Use the DAD Hospital data and answer the below questions.\n",
    "\n",
    "1.\tLoad the dataset in Jupyter Notebook using pandas\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset. Report the features, which are correlated at a cut-off of 0.70. What actions will you take on the features, which are highly correlated?\n",
    "3.\tBuild a new feature named BMI using body height and body weight. Include this as a part of the data frame created in step 1.\n",
    "4.\tPast medical history code has 175 instances of missing value (NaN). Impute ‘None’ as a label wherever the value is NaN for this feature.\n",
    "5.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "6.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "7.\tBuild a model using age as independent variable and cost of treatment as dependent variable.\n",
    "    > * Is age a significant feature in this model?\n",
    "    * What inferences can be drawn from this model? \n",
    "8.\tBuild a model with statsmodel.api to estimate the total cost to hospital. How do you interpret the model outcome? Report the model performance on the test set.\n",
    "9.\tBuild a model with statsmodel.formula.api to estimate the total cost to hospital and report the model performance on the test set. What difference do you observe in the model built here and the one built in step 8.\n",
    "10.\tBuild a model using sklearn package to estimate the total cost to hospital. What difference do you observe in this model compared to model built in step 8 and 9.\n",
    "11. Build a model using lasso, ridge and elastic net regression. What differences do you observe?\n",
    "12. Build model using gradient descent to get an intuition about the inner working of optimization algorithms.\n",
    "13. Build model using gradient descent with regularization to get an intution about the inner working of optimization algorithms.\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "|Sl.No.|Variable|\tDescription|\n",
    "|------|--------|--------------|\n",
    "|1|Age|\t Age of the patient in years|\n",
    "|2|Body Weight|\t Weight of the patient in Kilograms|\n",
    "|3|Body Height| \tHeight of the patient in cm|\n",
    "|4|HR Pulse|\t Pulse of patient at the time of admission|\n",
    "|5|BP-High|\t High BP of patient (Systolic)|\n",
    "|6|BP-Low|\t Low BP of patient (Diastolic)|\n",
    "|7|RR|\t Respiratory rate of patient|\n",
    "|8|HB|\t Hemoglobin count of patient|\n",
    "|9|Urea|\t Urea levels of patient|\n",
    "|10|Creatinine|\t Creatinine levels of patient|\n",
    "|11|Marital Status|\t Marital status of the patient|\n",
    "|12|Gender|\t  Gender code for patient|\n",
    "|13|Past Medical History Code|\t Code given to the past medical history of the Patient|\n",
    "|14|Mode of Arrival|\t Way in which the patient arrived the hospital|\n",
    "|15|State at the Time of Arrival|\t State in which the patient arrived|\n",
    "|16|Type of Admission|\t Type of admission for the patient|\n",
    "|17|Key Complaints Code|\t Codes given to the key complaints faced by the patient|\n",
    "|18|Total Cost to Hospital|\t Actual cost incurred by the hospital|\n",
    "|19|Total Length of Stay|\t Number of days patient stayed in the hospital|\n",
    "|20|Length of Stay - ICU|\t Number of days patient stayed in the ICU|\n",
    "|21|Length of Stay - Ward|\t Number of days patient stayed in the ward|\n",
    "|22|Implant used (Y/N)|\t Any implant done on the patient|\n",
    "|23|Cost of Implant|\t Total cost of all the implants done on the patient, if any|\n",
    "\n",
    "***\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "To know the environment with the pyhton kernal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn # visualization library based on matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the ast_note_interactivity kernel option to see the value of multiple statements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the display settings for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas will start looking from where your current python file is located. Therefore you can move from your current directory to where your data is located with '..'\n",
    "\n",
    "> * The single period . means current working directory\n",
    "* The double period .. means parent of the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv( \"../DAD_hospital/data/DAD_Case_Data_Corrected.csv\", \n",
    "                        sep = ',', na_values = ['', ' '])\n",
    "\n",
    "raw_df.columns = raw_df.columns.str.lower().str.replace('.', '_')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping SL No as these will not be used for any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?raw_df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if set(['sl no']).issubset(raw_df.columns):\n",
    "    raw_df.drop(['sl no'],axis=1, inplace=True)\n",
    "    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.describe(include='all').transpose()\n",
    "#raw_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get numeric features from the data and find the corelation amongst numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [x for x in raw_df.select_dtypes(include=[np.number])]\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features_df = raw_df.select_dtypes(include=[np.number])\n",
    "numerical_features_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [x for x in raw_df.select_dtypes(include=[np.object])]\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = raw_df.dropna(axis=0, how='any', thresh=None, \n",
    "                             subset=None, inplace=False)\n",
    "\n",
    "list(filter_df.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by printing the unique labels in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in categorical_features:\n",
    "    print(\"\\nThe unique labels in {} is {}\\n\".format(f, filter_df[f].unique()))\n",
    "    print(\"The values in {} is \\n{}\\n\".format(f,  filter_df[f].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clubbing some of the feature labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['past_medical_history_code']=np.where(\n",
    "        (filter_df['past_medical_history_code'] =='hypertension1') |\n",
    "         (filter_df['past_medical_history_code'] =='hypertension2') | \n",
    "         (filter_df['past_medical_history_code'] =='hypertension3'),\n",
    "    'hypertension', filter_df['past_medical_history_code'])\n",
    "\n",
    "filter_df['past_medical_history_code']=np.where(\n",
    "    (filter_df['past_medical_history_code'] =='Diabetes1') |\n",
    "    (filter_df['past_medical_history_code'] =='Diabetes2'), \n",
    "    'diabetes', filter_df['past_medical_history_code'])\n",
    "\n",
    "\n",
    "filter_df['key_complaints__code']=np.where(\n",
    "        (filter_df['key_complaints__code'] =='other- respiratory') |\n",
    "         (filter_df['key_complaints__code'] =='PM-VSD') | \n",
    "         (filter_df['key_complaints__code'] =='CAD-SVD') |\n",
    "        (filter_df['key_complaints__code'] =='CAD-VSD') |\n",
    "        (filter_df['key_complaints__code'] =='other-nervous') |\n",
    "        (filter_df['key_complaints__code'] =='other-general'), \n",
    "        'others', filter_df['key_complaints__code'])\n",
    "\n",
    "#filter_df.past_medical_history_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **groupby** function of pandas to summarize numerical features by each categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by (categorical_features):\n",
    "    std = filter_df.groupby(categorical_features).std()\n",
    "    mean = filter_df.groupby(categorical_features).mean()\n",
    "    return std, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the above function to group the numeric value by gender and marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,m =group_by('gender')\n",
    "s\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['bmi'] = filter_df.body_weight/(np.power((filter_df.body_height/100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Data\n",
    "\n",
    "Plot can be done using the callable functions of \n",
    "\n",
    ">1. pandas library (http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "2. matplotlib library (https://matplotlib.org/) or\n",
    "3. seaborn library (https://seaborn.pydata.org/) which is based on matplotlib and provides interface for drawing attractive statistical graphics.\n",
    "\n",
    "#### 3a. Visualizing the Data using seaborn\n",
    "\n",
    "Write a custom function to create bar plot to visualize the average of numeric features w.r.t each categorical feature. Say, average age w.r.t gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df[numerical_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(xlabel,ylabel):\n",
    "    sn.barplot(x = xlabel, y = ylabel, data= filter_df)\n",
    "    plt.xlabel(xlabel, size = 14)\n",
    "    plt.ylabel(ylabel, size = 14)\n",
    "    #plt.grid(True)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features_set = ['age','rr']\n",
    "categorical_features_set = ['gender','marital_status']\n",
    "\n",
    "for c in categorical_features_set:\n",
    "    for n in numerical_features_set:\n",
    "        bar_plot(c,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Approach 2:  Without dummy variable coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the name of all the models in any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(smf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = [x for x in filter_df if x not in ['body_weight','body_height',\n",
    "                                           'creatinine','state_at_the_time_of_arrival',\n",
    "                                           'total_amount_billed_to_the_patient','concession',\n",
    "                                          'actual_receivable_amount','total_length_of_stay',\n",
    "                                          'length_of_stay___icu','length_of_stay__ward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = filter_df.filter(X_features, axis =1)\n",
    "\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split( new_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the formula with the required set of variables to be used in model building. Formula takes the form as Y~X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_formula = 'total_cost_to_hospital ~ \\\n",
    "            C(gender) + \\\n",
    "            C(marital_status) + \\\n",
    "            C(key_complaints__code) + \\\n",
    "            C(past_medical_history_code) + \\\n",
    "            C(mode_of_arrival) + \\\n",
    "            C(type_of_admsn)+ \\\n",
    "            C(implant_used) + \\\n",
    "            age + hr_pulse + bp__high + bp_low + \\\n",
    "            rr +hb + urea + cost_of_implant + bmi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regression_model = smf.ols(formula=pass_formula, data=train_df).fit()\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the significant variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_vars (modelobject):\n",
    "    var_p_vals_df = pd.DataFrame(modelobject.pvalues)\n",
    "    var_p_vals_df['vars'] = var_p_vals_df.index\n",
    "    var_p_vals_df.columns = ['pvals', 'vars']\n",
    "    return list(var_p_vals_df[var_p_vals_df.pvals <= 0.05]['vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_vars = get_significant_vars(regression_model)\n",
    "significant_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on train data.\n",
    "Two ways to precit the outcome on the **train set**\n",
    "> * Use **predict** function of the model object \n",
    "* Use **get_prediction** function of the model object\n",
    "\n",
    "For the model with dummy variable coding explicetely done, we need to add the constant term to the test set. For the model with dummy variable coding carried out automatically, there is no need to add the constant term to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output with the model with no dummy variable coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretVarImp, echo=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_train_df = regression_model.predict((train_df))\n",
    "predict_train_df.head()\n",
    "\n",
    "predict_train_df = regression_model.get_prediction(train_df)\n",
    "predict_train_df.predicted_mean[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Evaluation - heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = regression_model.fittedvalues.copy()\n",
    "true_val = train_df['total_cost_to_hospital'].values.copy()\n",
    "residual = true_val - pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residual, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Evaluation - Test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "normality_plot = sm.qqplot(residual,line = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "def get_predictions ( test_actual, model, test_data ):\n",
    "    y_pred_df = pd.DataFrame( { 'actual': test_actual,\n",
    "                               'predicted': model.get_prediction((test_data)).predicted_mean})\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df = get_predictions( test_df.total_cost_to_hospital, regression_model, test_df)\n",
    "predict_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
