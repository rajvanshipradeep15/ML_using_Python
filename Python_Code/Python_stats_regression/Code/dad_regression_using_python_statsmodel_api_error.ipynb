{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\n",
    "OLS Regression using Python (statsmodel.api):</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\"><br>\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "### We will be using DAD hospital data in this exercise. Refer the Exhibit 1 to understand the feature list. Use the DAD Hospital data and answer the below questions.\n",
    "\n",
    "1.\tLoad the dataset in Jupyter Notebook using pandas\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset. Report the features, which are correlated at a cut-off of 0.70. What actions will you take on the features, which are highly correlated?\n",
    "3.\tBuild a new feature named BMI using body height and body weight. Include this as a part of the data frame created in step 1.\n",
    "4.\tPast medical history code has 175 instances of missing value (NaN). Impute ‘None’ as a label wherever the value is NaN for this feature.\n",
    "5.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "6.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "7.\tBuild a model using age as independent variable and cost of treatment as dependent variable.\n",
    "    > * Is age a significant feature in this model?\n",
    "    * What inferences can be drawn from this model? \n",
    "8.\tBuild a model with statsmodel.api to estimate the total cost to hospital. How do you interpret the model outcome? Report the model performance on the test set.\n",
    "9.\tBuild a model with statsmodel.formula.api to estimate the total cost to hospital and report the model performance on the test set. What difference do you observe in the model built here and the one built in step 8.\n",
    "10.\tBuild a model using sklearn package to estimate the total cost to hospital. What difference do you observe in this model compared to model built in step 8 and 9.\n",
    "11. Build a model using lasso, ridge and elastic net regression. What differences do you observe?\n",
    "12. Build model using gradient descent to get an intuition about the inner working of optimization algorithms.\n",
    "13. Build model using gradient descent with regularization to get an intution about the inner working of optimization algorithms.\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "|Sl.No.|Variable|\tDescription|\n",
    "|------|--------|--------------|\n",
    "|1|Age|\t Age of the patient in years|\n",
    "|2|Body Weight|\t Weight of the patient in Kilograms|\n",
    "|3|Body Height| \tHeight of the patient in cm|\n",
    "|4|HR Pulse|\t Pulse of patient at the time of admission|\n",
    "|5|BP-High|\t High BP of patient (Systolic)|\n",
    "|6|BP-Low|\t Low BP of patient (Diastolic)|\n",
    "|7|RR|\t Respiratory rate of patient|\n",
    "|8|HB|\t Hemoglobin count of patient|\n",
    "|9|Urea|\t Urea levels of patient|\n",
    "|10|Creatinine|\t Creatinine levels of patient|\n",
    "|11|Marital Status|\t Marital status of the patient|\n",
    "|12|Gender|\t  Gender code for patient|\n",
    "|13|Past Medical History Code|\t Code given to the past medical history of the Patient|\n",
    "|14|Mode of Arrival|\t Way in which the patient arrived the hospital|\n",
    "|15|State at the Time of Arrival|\t State in which the patient arrived|\n",
    "|16|Type of Admission|\t Type of admission for the patient|\n",
    "|17|Key Complaints Code|\t Codes given to the key complaints faced by the patient|\n",
    "|18|Total Cost to Hospital|\t Actual cost incurred by the hospital|\n",
    "|19|Total Length of Stay|\t Number of days patient stayed in the hospital|\n",
    "|20|Length of Stay - ICU|\t Number of days patient stayed in the ICU|\n",
    "|21|Length of Stay - Ward|\t Number of days patient stayed in the ward|\n",
    "|22|Implant used (Y/N)|\t Any implant done on the patient|\n",
    "|23|Cost of Implant|\t Total cost of all the implants done on the patient, if any|\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "To know the environment with the pyhton kernal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn # visualization library based on matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the ast_note_interactivity kernel option to see the value of multiple statements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the display settings for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas will start looking from where your current python file is located. Therefore you can move from your current directory to where your data is located with '..'\n",
    "\n",
    "> * The single period . means current working directory\n",
    "* The double period .. means parent of the current working directory\n",
    "\n",
    "Correct the path name in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = ##read the data\n",
    "raw_df.columns = raw_df.columns.str.lower().str.replace('.', '_')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping SL No as these will not be used for any analysis or model building. Refer to the use of `drop()` function of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the statistical summary of the data using describe method of pandas. Include the statistical summary of cateogical features as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code summarizes the numeric feature. Modify the code below to include description of categorical features as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get numeric features from the data and find the corelation amongst numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [x for x in raw_df.select_dtypes(include=[np.number])]\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_df = raw_df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get correlation between numerical features. Use the corr method from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ## your code here\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = # write your code here. Look for the method to be used on raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through to print the unique labels in each categorical features lists created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clubbing some of the feature labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['past_medical_history_code'] = np.where(\n",
    "        (filter_df['past_medical_history_code'] =='hypertension1') |\n",
    "         (filter_df['past_medical_history_code'] =='hypertension2') | \n",
    "         (filter_df['past_medical_history_code'] =='hypertension3'),\n",
    "    'hypertension', filter_df['past_medical_history_code'])\n",
    "\n",
    "filter_df['past_medical_history_code']=np.where(\n",
    "    (filter_df['past_medical_history_code'] =='Diabetes1') |\n",
    "    (filter_df['past_medical_history_code'] =='Diabetes2'), \n",
    "    'diabetes', filter_df['past_medical_history_code'])\n",
    "\n",
    "\n",
    "filter_df['key_complaints__code']=np.where(\n",
    "        (filter_df['key_complaints__code'] =='other- respiratory') |\n",
    "         (filter_df['key_complaints__code'] =='PM-VSD') | \n",
    "         (filter_df['key_complaints__code'] =='CAD-SVD') |\n",
    "        (filter_df['key_complaints__code'] =='CAD-VSD') |\n",
    "        (filter_df['key_complaints__code'] =='other-nervous') |\n",
    "        (filter_df['key_complaints__code'] =='other-general'), \n",
    "        'others', filter_df['key_complaints__code'])\n",
    "\n",
    "#filter_df.past_medical_history_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **groupby** function of pandas to summarize numerical features by each categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by (categorical_features):\n",
    "    std = filter_df.groupby(categorical_features).std()\n",
    "    mean = filter_df.groupby(categorical_features).mean()\n",
    "    return std, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the above function to group the numeric value by gender and marital_status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating BMI\n",
    "\n",
    "\\begin{equation}\n",
    "\\ BMI = \\frac{bodyweight}{bodyheigth_{in mtrs}^2}\n",
    "\\end{equation}\n",
    "\n",
    "Add a new feature to calculate BMI and include it as a part of filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['bmi'] = ## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Data\n",
    "\n",
    "Plot can be done using the callable functions of \n",
    "\n",
    ">1. pandas library (http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "2. matplotlib library (https://matplotlib.org/) or\n",
    "3. seaborn library (https://seaborn.pydata.org/) which is based on matplotlib and provides interface for drawing attractive statistical graphics.\n",
    "\n",
    "#### 3a. Visualizing the Data using seaborn\n",
    "\n",
    "Write a custom function to create bar plot to visualize the average of numeric features w.r.t each categorical feature. Say, average age w.r.t gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Call the function to plot the bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Approach 1:  With dummy variable coding\n",
    "\n",
    "### Dummy Variable coding\n",
    "\n",
    "Create a X feature list with the following feature not as a part of the features: 'body_weight','body_height',\n",
    "                                           'creatinine','state_at_the_time_of_arrival',\n",
    "                                           'total_amount_billed_to_the_patient','concession',\n",
    "                                          'actual_receivable_amount','total_length_of_stay',\n",
    "                                          'length_of_stay___icu','length_of_stay__ward',\n",
    "                                            'total_cost_to_hospital'\n",
    "\n",
    "Remove the response variable from the dataset¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = [x for x in filter_df if x not in ['body_weight','body_height', \n",
    "                                                'creatinine','state_at_the_time_of_arrival',\n",
    "                                                'total_amount_billed_to_the_patient',\n",
    "                                                'concession', 'actual_receivable_amount',\n",
    "                                                'total_length_of_stay', \n",
    "                                                'length_of_stay___icu',\n",
    "                                                'length_of_stay__ward', \n",
    "                                                'total_cost_to_hospital']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['gender','marital_status','key_complaints__code',\n",
    "                        'past_medical_history_code','mode_of_arrival','type_of_admsn','implant_used__y_n_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the code below to create a dummy variable coded column. Look for the use of pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_df = ## your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "encoded_X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = filter_df.filter(['total_cost_to_hospital'], axis =1)\n",
    "X = encoded_X_df\n",
    "Y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split using Python\n",
    "\n",
    "The train and test split can also be done using the **sklearn module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_test.shape\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "y_test.shape\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Using the **statsmodel.api** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretModel, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "regression_model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the significant variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_vars (modelobject):\n",
    "    var_p_vals_df = pd.DataFrame(modelobject.pvalues)\n",
    "    var_p_vals_df['vars'] = var_p_vals_df.index\n",
    "    var_p_vals_df.columns = ['pvals', 'vars']\n",
    "    return list(var_p_vals_df[var_p_vals_df.pvals <= 0.05]['vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_vars = get_significant_vars(regression_model)\n",
    "significant_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on train data.\n",
    "Two ways to precit the outcome on the **train set**\n",
    "> * Use **predict** function of the model object \n",
    "* Use **get_prediction** function of the model object\n",
    "\n",
    "For the model with dummy variable coding explicetely done, we need to add the constant term to the test set. For the model with dummy variable coding carried out automatically, there is no need to add the constant term to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output from model with dummy variable coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretVarImp, echo=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_train_df = regression_model.predict(sm.add_constant(X_train))\n",
    "predict_train_df.head()\n",
    "\n",
    "predict_train_df = regression_model.get_prediction(sm.add_constant(X_train))\n",
    "predict_train_df.predicted_mean[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Evaluation - heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = regression_model.fittedvalues.copy()\n",
    "true_val = y_train['total_cost_to_hospital'].values.copy()\n",
    "residual = true_val - pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residual, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Evaluation - Test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot = sm.qqplot(residual, line = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "def get_predictions ( test_actual, model, test_data ):\n",
    "    y_pred_df = pd.DataFrame( { 'actual': test_actual,\n",
    "                               'predicted': model.get_prediction(sm.add_constant(test_data)).predicted_mean})\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df = pd.DataFrame(get_predictions(y_test.total_cost_to_hospital, regression_model, X_test))\n",
    "predict_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
